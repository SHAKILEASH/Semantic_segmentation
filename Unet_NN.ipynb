{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from keras.models import Model\n",
    "from keras.layers import *\n",
    "from keras.optimizers import Adam\n",
    "from keras.callbacks import ModelCheckpoint, LearningRateScheduler\n",
    "from keras import backend as keras\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "import os\n",
    "import glob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_Data():\n",
    "    data_X = ImageDataGenerator(rotation_range=0.2,\n",
    "                    width_shift_range=0.05,\n",
    "                    height_shift_range=0.05,\n",
    "                    shear_range=0.05,\n",
    "                    zoom_range=0.05,\n",
    "                    horizontal_flip=True,\n",
    "                    fill_mode='nearest')\n",
    "    data_Y = ImageDataGenerator(rotation_range=0.2,\n",
    "                    width_shift_range=0.05,\n",
    "                    height_shift_range=0.05,\n",
    "                    shear_range=0.05,\n",
    "                    zoom_range=0.05,\n",
    "                    horizontal_flip=True,\n",
    "                    fill_mode='nearest')\n",
    "    train_X = data_X.flow_from_directory(\n",
    "     'data/train',\n",
    "        classes = ['image'],\n",
    "        class_mode = None,\n",
    "        color_mode = 'grayscale',\n",
    "        target_size = (256,256),\n",
    "        batch_size = 2,\n",
    "        save_to_dir = None,\n",
    "        save_prefix  = \"image\",\n",
    "        seed = 1)\n",
    "    train_Y = data_Y.flow_from_directory(\n",
    "     'data/train',\n",
    "        classes = ['label'],\n",
    "        class_mode = None,\n",
    "        color_mode = 'grayscale',\n",
    "        target_size = (256,256),\n",
    "        batch_size = 2,\n",
    "        save_to_dir = None,\n",
    "        save_prefix  = \"image\",\n",
    "        seed = 1)\n",
    "    train = zip(train_X,train_Y)\n",
    "    for (img,mask) in train:\n",
    "        if(np.max(img) > 1):\n",
    "            img = img / 255\n",
    "            mask = mask /255\n",
    "            mask[mask > 0.5] = 1\n",
    "            mask[mask <= 0.5] = 0\n",
    "    train_X = img  \n",
    "    train_Y = mask\n",
    "    return train_X,train_Y\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 30 images belonging to 1 classes.\n",
      "Found 30 images belonging to 1 classes.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR:root:Internal Python error in the inspect module.\n",
      "Below is the traceback from this internal error.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Shaki\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3326, in run_code\n",
      "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \"<ipython-input-3-4cb902a98820>\", line 1, in <module>\n",
      "    process_Data()\n",
      "  File \"<ipython-input-2-fe608fe88571>\", line 37, in process_Data\n",
      "    for (img,mask) in train:\n",
      "  File \"C:\\Users\\Shaki\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\keras_preprocessing\\image\\iterator.py\", line 104, in __next__\n",
      "    return self.next(*args, **kwargs)\n",
      "  File \"C:\\Users\\Shaki\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\keras_preprocessing\\image\\iterator.py\", line 116, in next\n",
      "    return self._get_batches_of_transformed_samples(index_array)\n",
      "  File \"C:\\Users\\Shaki\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\keras_preprocessing\\image\\iterator.py\", line 230, in _get_batches_of_transformed_samples\n",
      "    interpolation=self.interpolation)\n",
      "  File \"C:\\Users\\Shaki\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\keras_preprocessing\\image\\utils.py\", line 132, in load_img\n",
      "    img = img.resize(width_height_tuple, resample)\n",
      "  File \"C:\\Users\\Shaki\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\PIL\\Image.py\", line 1886, in resize\n",
      "    self.load()\n",
      "  File \"C:\\Users\\Shaki\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\PIL\\ImageFile.py\", line 253, in load\n",
      "    n, err_code = decoder.decode(b)\n",
      "KeyboardInterrupt\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Shaki\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2040, in showtraceback\n",
      "    stb = value._render_traceback_()\n",
      "AttributeError: 'KeyboardInterrupt' object has no attribute '_render_traceback_'\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Shaki\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\IPython\\core\\ultratb.py\", line 1101, in get_records\n",
      "    return _fixed_getinnerframes(etb, number_of_lines_of_context, tb_offset)\n",
      "  File \"C:\\Users\\Shaki\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\IPython\\core\\ultratb.py\", line 319, in wrapped\n",
      "    return f(*args, **kwargs)\n",
      "  File \"C:\\Users\\Shaki\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\IPython\\core\\ultratb.py\", line 353, in _fixed_getinnerframes\n",
      "    records = fix_frame_records_filenames(inspect.getinnerframes(etb, context))\n",
      "  File \"C:\\Users\\Shaki\\AppData\\Local\\Continuum\\anaconda3\\lib\\inspect.py\", line 1502, in getinnerframes\n",
      "    frameinfo = (tb.tb_frame,) + getframeinfo(tb, context)\n",
      "  File \"C:\\Users\\Shaki\\AppData\\Local\\Continuum\\anaconda3\\lib\\inspect.py\", line 1460, in getframeinfo\n",
      "    filename = getsourcefile(frame) or getfile(frame)\n",
      "  File \"C:\\Users\\Shaki\\AppData\\Local\\Continuum\\anaconda3\\lib\\inspect.py\", line 696, in getsourcefile\n",
      "    if getattr(getmodule(object, filename), '__loader__', None) is not None:\n",
      "  File \"C:\\Users\\Shaki\\AppData\\Local\\Continuum\\anaconda3\\lib\\inspect.py\", line 733, in getmodule\n",
      "    if ismodule(module) and hasattr(module, '__file__'):\n",
      "  File \"C:\\Users\\Shaki\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\tensorflow\\__init__.py\", line 50, in __getattr__\n",
      "    module = self._load()\n",
      "  File \"C:\\Users\\Shaki\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\tensorflow\\__init__.py\", line 44, in _load\n",
      "    module = _importlib.import_module(self.__name__)\n",
      "  File \"C:\\Users\\Shaki\\AppData\\Local\\Continuum\\anaconda3\\lib\\importlib\\__init__.py\", line 127, in import_module\n",
      "    return _bootstrap._gcd_import(name[level:], package, level)\n",
      "  File \"<frozen importlib._bootstrap>\", line 1006, in _gcd_import\n",
      "  File \"<frozen importlib._bootstrap>\", line 983, in _find_and_load\n",
      "  File \"<frozen importlib._bootstrap>\", line 967, in _find_and_load_unlocked\n",
      "  File \"<frozen importlib._bootstrap>\", line 677, in _load_unlocked\n",
      "  File \"<frozen importlib._bootstrap_external>\", line 728, in exec_module\n",
      "  File \"<frozen importlib._bootstrap>\", line 219, in _call_with_frames_removed\n",
      "  File \"C:\\Users\\Shaki\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\tensorflow_core\\contrib\\__init__.py\", line 43, in <module>\n",
      "    from tensorflow.contrib import cudnn_rnn\n",
      "  File \"C:\\Users\\Shaki\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\tensorflow_core\\contrib\\cudnn_rnn\\__init__.py\", line 38, in <module>\n",
      "    from tensorflow.contrib.cudnn_rnn.python.layers import *\n",
      "  File \"C:\\Users\\Shaki\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\tensorflow_core\\contrib\\cudnn_rnn\\__init__.py\", line 38, in <module>\n",
      "    from tensorflow.contrib.cudnn_rnn.python.layers import *\n",
      "  File \"C:\\Users\\Shaki\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\tensorflow_core\\contrib\\cudnn_rnn\\python\\layers\\__init__.py\", line 23, in <module>\n",
      "    from tensorflow.contrib.cudnn_rnn.python.layers.cudnn_rnn import *\n",
      "  File \"C:\\Users\\Shaki\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\tensorflow_core\\contrib\\cudnn_rnn\\python\\layers\\cudnn_rnn.py\", line 20, in <module>\n",
      "    from tensorflow.contrib.cudnn_rnn.python.ops import cudnn_rnn_ops\n",
      "  File \"C:\\Users\\Shaki\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\tensorflow_core\\contrib\\cudnn_rnn\\python\\ops\\cudnn_rnn_ops.py\", line 22, in <module>\n",
      "    from tensorflow.contrib.rnn.python.ops import lstm_ops\n",
      "  File \"C:\\Users\\Shaki\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\tensorflow_core\\contrib\\rnn\\__init__.py\", line 93, in <module>\n",
      "    from tensorflow.contrib.rnn.python.ops.rnn_cell import *\n",
      "  File \"C:\\Users\\Shaki\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\tensorflow_core\\contrib\\rnn\\python\\ops\\rnn_cell.py\", line 24, in <module>\n",
      "    from tensorflow.contrib.layers.python.layers import layers\n",
      "  File \"C:\\Users\\Shaki\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\tensorflow_core\\contrib\\layers\\__init__.py\", line 116, in <module>\n",
      "    from tensorflow.contrib.layers.python.layers import *\n",
      "  File \"C:\\Users\\Shaki\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\tensorflow_core\\contrib\\layers\\python\\layers\\__init__.py\", line 33, in <module>\n",
      "    from tensorflow.contrib.layers.python.layers.target_column import *\n",
      "  File \"C:\\Users\\Shaki\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\tensorflow_core\\contrib\\layers\\python\\layers\\target_column.py\", line 24, in <module>\n",
      "    from tensorflow.contrib.losses.python.losses import loss_ops\n",
      "  File \"C:\\Users\\Shaki\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\tensorflow_core\\contrib\\losses\\__init__.py\", line 25, in <module>\n",
      "    from tensorflow.contrib.losses.python import metric_learning\n",
      "  File \"C:\\Users\\Shaki\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\tensorflow_core\\contrib\\losses\\python\\metric_learning\\__init__.py\", line 25, in <module>\n",
      "    from tensorflow.contrib.losses.python.metric_learning.metric_loss_ops import *\n",
      "  File \"C:\\Users\\Shaki\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\tensorflow_core\\contrib\\losses\\python\\metric_learning\\metric_loss_ops.py\", line 34, in <module>\n",
      "    from sklearn import metrics\n",
      "  File \"C:\\Users\\Shaki\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\__init__.py\", line 76, in <module>\n",
      "    from .base import clone\n",
      "  File \"C:\\Users\\Shaki\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\base.py\", line 16, in <module>\n",
      "    from .utils import _IS_32BIT\n",
      "  File \"C:\\Users\\Shaki\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\utils\\__init__.py\", line 20, in <module>\n",
      "    from .validation import (as_float_array,\n",
      "  File \"C:\\Users\\Shaki\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 21, in <module>\n",
      "    from .fixes import _object_dtype_isnan\n",
      "  File \"C:\\Users\\Shaki\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\utils\\fixes.py\", line 18, in <module>\n",
      "    from scipy.sparse.linalg import lsqr as sparse_lsqr  # noqa\n",
      "  File \"C:\\Users\\Shaki\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\scipy\\sparse\\linalg\\__init__.py\", line 117, in <module>\n",
      "    from .matfuncs import *\n",
      "  File \"C:\\Users\\Shaki\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\scipy\\sparse\\linalg\\matfuncs.py\", line 19, in <module>\n",
      "    import scipy.special\n",
      "  File \"C:\\Users\\Shaki\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\scipy\\special\\__init__.py\", line 637, in <module>\n",
      "    from . import _basic\n",
      "  File \"C:\\Users\\Shaki\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\scipy\\special\\_basic.py\", line 674, in <module>\n",
      "    def h2vp(v, z, n=1):\n",
      "KeyboardInterrupt\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m"
     ]
    }
   ],
   "source": [
    "def Unet_model():\n",
    "    inputs = Input(input_size)\n",
    "    conv1 = Conv2D(64, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(inputs)\n",
    "    conv1 = Conv2D(64, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(conv1)\n",
    "    pool1 = MaxPooling2D(pool_size=(2, 2))(conv1)\n",
    "    conv2 = Conv2D(128, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(pool1)\n",
    "    conv2 = Conv2D(128, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(conv2)\n",
    "    pool2 = MaxPooling2D(pool_size=(2, 2))(conv2)\n",
    "    conv3 = Conv2D(256, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(pool2)\n",
    "    conv3 = Conv2D(256, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(conv3)\n",
    "    pool3 = MaxPooling2D(pool_size=(2, 2))(conv3)\n",
    "    conv4 = Conv2D(512, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(pool3)\n",
    "    conv4 = Conv2D(512, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(conv4)\n",
    "    drop4 = Dropout(0.5)(conv4)\n",
    "    pool4 = MaxPooling2D(pool_size=(2, 2))(drop4)\n",
    "\n",
    "    conv5 = Conv2D(1024, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(pool4)\n",
    "    conv5 = Conv2D(1024, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(conv5)\n",
    "    drop5 = Dropout(0.5)(conv5)\n",
    "\n",
    "    up6 = Conv2D(512, 2, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(UpSampling2D(size = (2,2))(drop5))\n",
    "    merge6 = concatenate([drop4,up6], axis = 3)\n",
    "    conv6 = Conv2D(512, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(merge6)\n",
    "    conv6 = Conv2D(512, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(conv6)\n",
    "\n",
    "    up7 = Conv2D(256, 2, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(UpSampling2D(size = (2,2))(conv6))\n",
    "    merge7 = concatenate([conv3,up7], axis = 3)\n",
    "    conv7 = Conv2D(256, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(merge7)\n",
    "    conv7 = Conv2D(256, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(conv7)\n",
    "\n",
    "    up8 = Conv2D(128, 2, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(UpSampling2D(size = (2,2))(conv7))\n",
    "    merge8 = concatenate([conv2,up8], axis = 3)\n",
    "    conv8 = Conv2D(128, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(merge8)\n",
    "    conv8 = Conv2D(128, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(conv8)\n",
    "\n",
    "    up9 = Conv2D(64, 2, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(UpSampling2D(size = (2,2))(conv8))\n",
    "    merge9 = concatenate([conv1,up9], axis = 3)\n",
    "    conv9 = Conv2D(64, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(merge9)\n",
    "    conv9 = Conv2D(64, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(conv9)\n",
    "    conv9 = Conv2D(2, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(conv9)\n",
    "    conv10 = Conv2D(1, 1, activation = 'sigmoid')(conv9)\n",
    "\n",
    "    model = Model(input = inputs, output = conv10)\n",
    "\n",
    "    model.compile(optimizer = Adam(lr = 1e-4), loss = 'binary_crossentropy', metrics = ['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
